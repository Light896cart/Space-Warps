import torch

from src.data.dataloader import create_train_val_dataloaders
from src.data.dataset import Space_Galaxi
from src.model.progressive_search import progressive_architecture_search
from src.utils.logging import summarize_progressive_growth
from src.utils.seeding import set_seed

import hydra
from omegaconf import DictConfig, OmegaConf

# @hydra.main(config_path='conf',config_name='base',version_base=None)
def main() -> None:
    # path = cfg.data.path
    # üå± 1. –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
    print("üîß –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏...")
    set_seed(42)
    ver = r'D:\Code\Space_Warps\train'
    # üì• 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüì• –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
    train_loader, val_loader = create_train_val_dataloaders(
        csv_path=None,                # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø—É—Ç—å
        img_dir_path=None,
        dataset=Space_Galaxi,
        train_ratio=0.9,
        fraction=0.02,                 # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 100% –¥–∞–Ω–Ω—ã—Ö
        batch_size=32,
        num_workers=0,
        seed=42                       # –¥–ª—è DataLoader
    )
    # üß† 3. –ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    print("\nüöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã...")
    model, history = progressive_architecture_search(
        train_loader=train_loader,
        val_loader=val_loader,
        max_layers=10,
        k_candidates=[[9, 21, 54,120],[21,50,86,140],[20,40,60,80],[9,21,54,90]],    # k: –º–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è —á–∏—Å–ª–∞ –∫–∞–Ω–∞–ª–æ–≤ (–∫–∞–Ω–∞–ª—ã = 3 * k)
        epochs_per_eval=1,            # —Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö —É—á–∏—Ç—å –∫–∞–∂–¥—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç
        lr=1e-3,
        device="cuda" if torch.cuda.is_available() else "cpu",
        seed=42,
        copy_weights=True
    )

    # üìä 4. –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç
    if len(history) > 0:
        best_val_acc = max(h["val_acc"] for h in history)  # ‚úÖ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
    else:
        best_val_acc = 0.0

    print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞...")
    summary = summarize_progressive_growth(
        history=history,
        model=model,
        best_val_acc=best_val_acc,
        save_path=r"D:\Code\Space_Warps\result\progressive_summary.json",
        show_plot=True
    )

    # ‚úÖ 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if summary:
        model_save_path = "results/best_progressive_model.pth"
        torch.save(model.state_dict(), model_save_path)
        print(f"‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_save_path}")

    print("\nüéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")


# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    main()

import matplotlib.pyplot as plt
import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from PIL import Image
from torchvision import transforms

import os
#
class Space_Galaxi(Dataset):
    def __init__(self,csv_path,img_dir_path,transform=None):
        self.df = pd.read_csv(
            csv_path,
            sep=',',  # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å ‚Äî –∑–∞–ø—è—Ç–∞—è
            quotechar='"',  # –∫–∞–≤—ã—á–∫–∏ ‚Äî "
            engine='python',  # –µ—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–π –¥–≤–∏–∂–æ–∫ –ø–∞–¥–∞–µ—Ç
        )
        self.img_dir_path = img_dir_path
        self.transform = transform
    def __len__(self):
        return len(self.df)

    def __getitem__(self, item):
        id = self.df['id'].iloc[item]
        obj = self.df['class'].iloc[item]
        z = self.df['z'].iloc[item]
        z_err = self.df['z_err'].iloc[item]

        z_features = torch.tensor([z,z_err])
        image_path = os.path.join(self.img_dir_path, f"{id}.jpg")
        image = Image.open(image_path)  # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if self.transform:
            image = self.transform(image)
        return image,obj,z_features

class Subset(Dataset):
    def __init__(self, dataset, indices):
        self.dataset = dataset
        self.indices = indices

    def __getitem__(self, idx):
        return self.dataset[self.indices[idx]]  # ‚Üê –∫–ª—é—á–µ–≤–∞—è —Å—Ç—Ä–æ—á–∫–∞!

    def __len__(self):
        return len(self.indices)

# class Space_Galaxi(Dataset):
#     def __init__(self,img_dir_path,csv_path=None,transform=None):
#         self.img_dir_path = img_dir_path
#         image_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'}
#         self.image_names = [f for f in os.listdir(img_dir_path) if os.path.isfile(os.path.join(img_dir_path, f)) and os.path.splitext(f)[1].lower() in image_extensions]
#         self.transform = transform
#
#     def __len__(self):
#         return len(self.image_names)
#
#     def __getitem__(self, item):
#         img = self.image_names[item]
#         label = 0 if 'dog' in img else 1 if 'cat' in img else None
#         image_path = os.path.join(self.img_dir_path,img)
#         image = Image.open(image_path).convert("RGB")  # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
#         if self.transform:
#             transformed = self.transform(image)  # ‚Üê –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç {'image': tensor, 'rotation_angle': float}
#             # image_tensor = transformed['image']
#             # rotation_angle = transformed['rotation_angle']
#             # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–Ω–∑–æ—Ä, —É–≥–æ–ª –∏ –º–µ—Ç–∫—É
#         return transformed,label

# # –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø—É—Ç–∏
# csv_path = r'D:\Code\Space_Warps\spall_csv_chunks_lazy\spall_chunk_0001.csv'
# img_dir_path = r'D:\Code\Space_Warps\data\image_data\img_csv_0001'
#
# # –ü—Ä–æ–≤–µ—Ä–∫–∞
# if not os.path.exists(csv_path):
#     raise FileNotFoundError(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
# if not os.path.exists(img_dir_path):
#     raise FileNotFoundError(f"–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {img_dir_path}")
#
# reg = Space_Galaxi(csv_path, img_dir_path=img_dir_path)
#
# # –ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞
# for i, (ra, dec, image) in enumerate(reg):
#     print(f"{ra}, {dec}")
#     plt.figure(figsize=(5, 5))
#     plt.imshow(image)
#     plt.axis('off')
#     plt.title(f"ID: {reg.df['id'].iloc[i]}, RA: {ra}, Dec: {dec}")
#     plt.show()
#     print(i)
#     print('-' * 50)
#
# # files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]
# # print(files)

from typing import Optional, Tuple

import pandas as pd
import torch
from pathlib import Path
from torchvision.transforms import InterpolationMode
from torch.utils.data import DataLoader, Dataset

from src.data.dataset import Subset
from src.preprocessing.augmentation import train_transformer
from torchvision import transforms


def create_train_val_dataloaders(
    csv_path: Optional[str] = None,
    img_dir_path: Optional[str] = None,
    train_transform: Optional[transforms.Compose] = None,
    val_transform: Optional[transforms.Compose] = None,
    fraction: float = 1.0,
    train_ratio: float = 0.9,
    batch_size: int = 64,
    seed: int = 42,
    num_workers: int = 3,
    pin_memory: bool = False,
    dataset: Dataset = None,
) -> Tuple[DataLoader, DataLoader]:
    """
        –°–æ–∑–¥–∞—ë—Ç DataLoader'—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏,
        –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–æ–ª–∏ –¥–∞–Ω–Ω—ã—Ö, –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º.

        Args:
            csv_path: –ü—É—Ç—å –∫ CSV —Å –º–µ—Ç–∫–∞–º–∏. –ï—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç.
            img_dir_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
            train_transform: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è train (augmentations). –ï—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç.
            val_transform: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è val (–±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π). –ï—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç.
            fraction: –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.1 –¥–ª—è 10%).
            train_ratio: –î–æ–ª—è train –≤ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ (–æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî val).
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞.
            seed: Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏.
            num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
            pin_memory: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ pinned memory (—É—Å–∫–æ—Ä—è–µ—Ç –ø–µ—Ä–µ–¥–∞—á—É –Ω–∞ GPU).

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (train_loader, val_loader)

        Raises:
            FileNotFoundError: –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω CSV –∏–ª–∏ –ø–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
            ValueError: –ü—Ä–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö.
        """
    # --- –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ---
    if not 0.0 < fraction <= 1.0:
        raise ValueError(f"fraction must be in (0, 1], got {fraction}")
    if not 0.0 < train_ratio < 1.0:
        raise ValueError(f"train_ratio must be in (0, 1), got {train_ratio}")
    if batch_size <= 0:
        raise ValueError(f"batch_size must be positive, got {batch_size}")

    # --- üìÅ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–µ–π ---

    if csv_path is None:
        csv_path = r'D:\Code\Space_Warps\data\reg\balanced_2001_by_class_cycle.csv'
    else:
        csv_path = Path(csv_path)

    if img_dir_path is None:
        img_dir_path = r'D:\Code\Space_Warps\data\image_data\img_csv'
    else:
        img_dir_path = Path(img_dir_path)

    if not csv_path:
        raise FileNotFoundError(f"CSV file not found: {csv_path}")
    if not img_dir_path:
        raise FileNotFoundError(f"Image directory not found: {img_dir_path}")

    # --- –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ ---
    if val_transform is None:
        val_transform = transforms.Compose([
            transforms.Resize((224, 224), interpolation=InterpolationMode.BILINEAR),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])
    if train_transform is None:
        train_transform = train_transformer

    # --- üß© –°–æ–∑–¥–∞—ë–º –æ–¥–∏–Ω –¥–∞—Ç–∞—Å–µ—Ç –±–µ–∑ transform (–±—É–¥–µ–º –ø—Ä–∏–º–µ–Ω—è—Ç—å —á–µ—Ä–µ–∑ collate_fn –∏–ª–∏ –≤ Subset?) ---
    # –ù–æ –ª—É—á—à–µ: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω –¥–∞—Ç–∞—Å–µ—Ç, –∞ transform –∑–∞–¥–∞–≤–∞—Ç—å –≤ Subset —á–µ—Ä–µ–∑ –æ–±—ë—Ä—Ç–∫—É
    # –û–¥–Ω–∞–∫–æ PyTorch –Ω–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–µ–Ω—è—Ç—å transform —É Subset –Ω–∞–ø—Ä—è–º—É—é ‚Üí –æ–±—Ö–æ–¥: –¥–µ—Ä–∂–∞—Ç—å –¥–≤–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞, –Ω–æ —Å shared data

    # üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω —Ä–∞–∑ —á—Ç–µ–Ω–∏–µ CSV, –∫—ç—à–∏—Ä—É–µ–º –º–µ—Ç–∫–∏
    df = pd.read_csv(csv_path)
    # total_size = len(df)
    total_size = 25000

    subset_size = int(fraction * total_size)
    if subset_size == 0:
        raise ValueError("Fraction is too small, subset_size = 0")

    # --- üîÅ –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ ---
    generator = torch.Generator().manual_seed(seed)
    indices = torch.randperm(total_size, generator=generator).tolist()
    subset_indices = indices[:subset_size]

    train_split = int(train_ratio * len(subset_indices))
    train_indices = subset_indices[:train_split]
    val_indices = subset_indices[train_split:]

    if len(train_indices) == 0:
        raise ValueError("Train split is empty after applying fraction and ratio.")
    if len(val_indices) == 0:
        raise ValueError("Validation split is empty after applying fraction and ratio.")

# --- üì¶ –î–≤–∞ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏ ---
    # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ: –æ–Ω–∏ –¥–µ–ª—è—Ç –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –≥—Ä—É–∑–∏—Ç –≤—Å—ë –≤ –ø–∞–º—è—Ç—å —Å—Ä–∞–∑—É)
    train_dataset = dataset(csv_path=str(csv_path), img_dir_path=str(img_dir_path), transform=train_transform)
    val_dataset = dataset(csv_path=str(csv_path), img_dir_path=str(img_dir_path), transform=val_transform)

    train_subset = Subset(train_dataset, train_indices)
    val_subset = Subset(val_dataset, val_indices)

    # --- üöö DataLoader ---
    train_loader = DataLoader(
        train_subset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
        generator=generator,
    )

    val_loader = DataLoader(
        val_subset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
        generator=generator,
    )

    print(f"‚úÖ DataLoader created:")
    print(f"   Total dataset size: {total_size}")
    print(f"   Used fraction: {fraction:.1%} ‚Üí {subset_size} samples")
    print(f"   Train: {len(train_indices)} | Val: {len(val_indices)}")
    print(f"   Batch size: {batch_size}, Workers: {num_workers}")

    return train_loader, val_loader

import random

import matplotlib.pyplot as plt
import torch
import torchvision.transforms as T
from PIL import Image
from torchvision.transforms import InterpolationMode
import numpy as np

# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ---
IMG_SIZE = 224
PAD_SIZE = 40
CROP_SIZE = IMG_SIZE

# --- –ö–∞—Å—Ç–æ–º–Ω—ã–π —à—É–º ---
class AddGaussianNoise:
    def __init__(self, mean=0.0, std=0.02):
        self.mean = mean
        self.std = std
    def __call__(self, tensor):
        noise = torch.randn_like(tensor) * self.std + self.mean
        return tensor + noise


class RandomRotationWithAngle:
    def __init__(self, degrees, interpolation=InterpolationMode.BILINEAR, expand=False):
        self.degrees = degrees
        self.interpolation = interpolation
        self.expand = expand

    def __call__(self, img):
        rotate = random.uniform(-self.degrees, self.degrees)

        # –ü–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img_rotated = T.functional.rotate(img, rotate, interpolation=self.interpolation, expand=self.expand)

        return {
            'image': img_rotated,
            'rotation_angle': img_rotated
        }

class DictTransform:
    """–û–±—ë—Ä—Ç–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–º–µ–Ω—è–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é —Ç–æ–ª—å–∫–æ –∫ 'image' –≤ —Å–ª–æ–≤–∞—Ä–µ"""
    def __init__(self, transform):
        self.transform = transform

    def __call__(self, data):
        # data = {'image': PIL/tensor, 'rotation_angle': float}
        img = data['image']
        angle = data['rotation_angle']

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        img_transformed = self.transform(img)

        return {
            'image': img_transformed,
            'rotation_angle': angle
        }

    def __repr__(self):
        return f"DictTransform({self.transform})"

# # --- –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è ---
# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ---
IMG_SIZE = 224

# --- –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ---
train_transformer = T.Compose([
    # –ù–∞—á–∏–Ω–∞–µ–º —Å PIL Image
    T.ToTensor(),
    T.Resize((IMG_SIZE, IMG_SIZE), interpolation=InterpolationMode.BILINEAR),

"""
model_architecture.py

–û–ø–∏—Å–∞–Ω–∏–µ:
    –ë–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏, —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ PyTorch.
    –ú–æ–¥–µ–ª—å –º–æ–∂–Ω–æ –Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å –∏–ª–∏ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É
    (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Ä–µ–≥—Ä–µ—Å—Å–∏—è, —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏ —Ç.–¥.).

–ê–≤—Ç–æ—Ä: Senior ML Engineer
–î–∞—Ç–∞: 2025-04-05
"""
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split

from torchvision import transforms

# –ü—Ä–æ—Å—Ç–æ–π transforms: –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä
transform = transforms.Compose([
    transforms.ToTensor(),          # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Ç–µ–Ω–∑–æ—Ä PyTorch
])

class ProgressiveModel(nn.Module):
    def __init__(self, extra_input_dim=2,class_data=2):
        super().__init__()
        self.blocks = nn.ModuleList()
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.classifier = None

        self.class_data = class_data
        self.extra_input_dim = extra_input_dim

        self.extra_proj = nn.Sequential(
            nn.Linear(self.extra_input_dim, 32),  # —Ä–∞—Å—à–∏—Ä—è–µ–º —Å–∫–∞–ª—è—Ä –≤ –≤–µ–∫—Ç–æ—Ä 32
            nn.ReLU(),
            nn.Dropout(0.3)  # –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ
        )


    def add_block(self, in_channels, out_channels,check_add=0):
        block = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.Dropout2d(0.2),
            nn.MaxPool2d(2)
        )
        if check_add == 0:
            self.blocks.append(block)
        else:
            del self.blocks[-1]
            self.blocks.append(block)
        self._update_classfic(out_channels)

    # def _update_classfic(self,output_line):
    #     self.classifier = nn.Sequential(
    #         nn.Dropout(0.2),
    #         nn.Linear(output_line + (32 if self.extra_input_dim > 0 else 0), self.class_data)
    #     )

    def _update_classfic(self,output_line):
        self.classifier = nn.Sequential(
            nn.Dropout(0.2),
            nn.Linear(output_line + (32 if self.extra_input_dim > 0 else 0), self.class_data)
        )
    def forward(self, x, extra=None):
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for block in self.blocks:
            x = block(x)
        x = self.global_pool(x)
        x = torch.flatten(x, 1)

        if extra is not None:
            extra_features = self.extra_proj(extra.float())  # [B, 32]
            x = torch.cat([x, extra_features], dim=1)
        x = self.classifier(x)
        return x

from typing import List

import torch
import torch.nn as nn
from torch.utils.data import DataLoader

from src.model.model_architecture import ProgressiveModel
from src.model.train_eval import train_and_evaluate_model



def progressive_architecture_search(
    train_loader: DataLoader,
    val_loader: DataLoader,
    max_layers: int = 10,
    k_candidates: List[int] = None,
    epochs_per_eval: int = 5,
    lr: float = 1e-3,
    device: str = None,
    seed: int = 42,
    copy_weights:bool = True
):
    """
    –ü–æ—à–∞–≥–æ–≤–æ –Ω–∞—Ä–∞—â–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å, –≤—ã–±–∏—Ä–∞—è –Ω–∞–∏–ª—É—á—à–∏–π –±–ª–æ–∫ (–ø–æ val_acc) –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ.

    Args:
        train_loader, val_loader: –¥–∞–Ω–Ω—ã–µ
        max_layers: –º–∞–∫—Å. —á–∏—Å–ª–æ –±–ª–æ–∫–æ–≤
        k_candidates: —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π k (–∫–∞–Ω–∞–ª—ã = base_channels * k)
        epochs_per_eval: —Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö —É—á–∏—Ç—å –∫–∞–∂–¥—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç
        lr: learning rate
        device: cuda/cpu
        seed: –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å

    Returns:
        –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∏ –∏—Å—Ç–æ—Ä–∏—è –ø–æ–∏—Å–∫–∞
    """
    if k_candidates is None:
        k_candidates = [[3, 9, 27, 81]]  # –Ω–∞–ø—Ä–∏–º–µ—Ä

    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    # üå± –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    # üß± –ù–∞—á–∏–Ω–∞–µ–º —Å –ø—É—Å—Ç–æ–π –º–æ–¥–µ–ª–∏
    model = ProgressiveModel(extra_input_dim=0,class_data=2).to(device)
    best_candidate_state = None
    channel_image = 3
    best_val_acc = 0.0
    best_k = None
    best_c = None
    history = []
    print("üîç –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã...")
    for quantity_blocks in range(len(k_candidates)):
        print(f"\n--- [–®–∞–≥ {quantity_blocks + 1}] –ü–æ–¥–±–æ—Ä —Å–ª–µ–¥—É—é—â–µ–≥–æ –±–ª–æ–∫–∞ ---")
        # log_system_usage(f"–ù–∞—á–∞–ª–æ —à–∞–≥–∞ {quantity_blocks + 1}")
        weight_model = None
        best_acc_for_layer = 0.0
        bias_model = None
        for i,candidat in enumerate(k_candidates[quantity_blocks]):
            # log_system_usage(f"–ü–µ—Ä–µ–¥ add_block {i+1}")
            out_channels = channel_image if quantity_blocks == 0 else model.blocks[-1][0].out_channels if i==0 else model.blocks[-2][0].out_channels
            model.add_block(out_channels,candidat,check_add=i)

            # log_system_usage(f"–ü–æ—Å–ª–µ add_block {i + 1}")
            # üîÅ –ü–µ—Ä–µ–Ω–æ—Å–∏–º –≤–µ—Å–∞, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ
            if weight_model is not None and len(model.blocks) > 0:
                target_conv = model.blocks[-1][0]  # –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ª–æ–π
                src_shape = weight_model.shape[1]  # [N, C, K, K] ‚Üí C = in_channels
                tgt_in_ch = target_conv.weight.shape[1]

                # –ï—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç ‚Äî —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞, –Ω–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ —Å–æ–≤–ø–∞–¥–∞—é—Ç
                # –ö–æ–ø–∏—Ä—É–µ–º –≤–µ—Å–∞ —Å —É—á—ë—Ç–æ–º —á–∏—Å–ª–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
                num_copy = min(target_conv.out_channels, weight_model.shape[0])

                # –ö–æ–ø–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ num_copy —Ñ–∏–ª—å—Ç—Ä–æ–≤
                with torch.no_grad():
                    target_conv.weight.data[:num_copy, :, :, :].copy_(weight_model[:num_copy, :, :, :])

                    # –ï—Å–ª–∏ —Ü–µ–ª–µ–≤–æ–π —Å–ª–æ–π –±–æ–ª—å—à–µ ‚Äî –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Å—Ç–∞—Ç–æ–∫
                    if target_conv.out_channels > num_copy:
                        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
                        new_filters = target_conv.out_channels - num_copy
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Kaiming –∏–ª–∏ –º–∞–ª—ã–π —à—É–º
                        nn.init.kaiming_normal_(
                            target_conv.weight.data[num_copy:, :, :, :],
                            mode='fan_in',
                            nonlinearity='relu'
                        )

            # üî¨ –û—Ü–µ–Ω–∏–≤–∞–µ–º (—Å —Ç–µ–º–∏ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏!)
            result = train_and_evaluate_model(
                model=model,
                train_loader=train_loader,
                val_loader=val_loader,
                epochs=epochs_per_eval,
                lr=lr,
                weight_model=weight_model,
                device=device,
                save_best_path=None,  # –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç
                verbose=True,
            )
            # log_system_usage(f"–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ {i + 1}")
            acc = result["best_val_acc"]
            if copy_weights:
                new_weight = result["new_weight"]
                new_bias = result["new_bias"]
                max_index = len(k_candidates[quantity_blocks]) - 1
                next_idx = min(i + 1, max_index)
                next_candidat = k_candidates[quantity_blocks][next_idx]
                number_repeat = next_candidat // candidat
                print(f'üîÅ number_repeat = {number_repeat} (candidat={candidat}, next={next_candidat})')
                weight_model = new_weight.detach().repeat(number_repeat, 1, 1, 1)  # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ detach()
                bias_model = new_bias.detach().repeat(number_repeat) if new_bias is not None else None
                # üî• –î–û–ë–ê–í–õ–Ø–ï–ú –°–õ–£–ß–ê–ô–ù–û–°–¢–¨: weight noise (jitter)
                # –®—É–º ~ N(0, œÉ), –≥–¥–µ œÉ = 0.1 * std(–≤–µ—Å–æ–≤)
                noise_std = 0.03 * weight_model.std()
                weight_model += torch.randn_like(weight_model) * noise_std

                # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è bias (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if bias_model is not None:
                    bias_noise_std = 0.1 * bias_model.std()
                    bias_model += torch.randn_like(bias_model) * bias_noise_std
            else:
                weight_model = None
                bias_model = None
            print(f"    ‚Üí val_acc = {acc:.4f}")
            if acc > best_acc_for_layer:
                best_acc_for_layer = acc
                best_k = candidat
                best_c = out_channels
                best_candidate_state = {k: v.detach().clone() for k, v in model.state_dict().items()} # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞
        # üèÅ –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—Ç–æ–∏—Ç –ª–∏ —Ä–∞—Å—Ç–∏
        weight_model = None
        # log_system_usage(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
        if best_acc_for_layer > best_val_acc:
            model.add_block(best_c, best_k, check_add=1)
            model.load_state_dict(best_candidate_state, strict=False)
            best_val_acc = best_acc_for_layer

            history.append({
                "layer": quantity_blocks + 1,
                "k": best_k,
                "channels": best_c,
                "val_acc": best_val_acc
            })

            print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –±–ª–æ–∫ {quantity_blocks + 1}: k={best_k} ‚Üí {best_c} –∫–∞–Ω–∞–ª–æ–≤, acc={best_val_acc:.4f}")
        else:
            print("‚ùå –ù–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è ‚Äî –æ—Å—Ç–∞–Ω–æ–≤.")
            break

    print(f"\n‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à—ë–Ω. –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {len(model.blocks)} –±–ª–æ–∫–æ–≤, acc={best_val_acc:.4f}")
    return model, history
from typing import Optional, Dict, Any

import torch.optim as optim
import torch
import torch.nn as nn
from tqdm import tqdm
from torch.utils.data import DataLoader

def train_and_evaluate_model(
    model: nn.Module,
    train_loader: DataLoader,
    val_loader: DataLoader,
    epochs: int = 10,
    lr: float = 1e-3,
    device: str = None,
    save_best_path: str = "best_model.pth",
    verbose: bool = True,
    seed: int = 42,
    weight_model: Optional[torch.Tensor] = None,
) -> Dict[str, Any]:
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –µ—ë –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª—É—á—à—É—é –ø–æ accuracy –º–æ–¥–µ–ª—å.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ–∫—É—â–∏–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ (warm-start).

    Args:
        model: PyTorch –º–æ–¥–µ–ª—å (—É–∂–µ –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —Å–ª–æ–∏)
        train_loader: DataLoader –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        val_loader: DataLoader –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
        lr: –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
        device: 'cuda' –∏–ª–∏ 'cpu'. –ï—Å–ª–∏ None ‚Äî –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.
        save_best_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        verbose: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –ª–æ–≥–∏
        seed: Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ –æ–±—É—á–µ–Ω–∏—è

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
            - best_val_acc: –ª—É—á—à–∞—è accuracy –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            - train_losses: loss –ø–æ —ç–ø–æ—Ö–∞–º
            - val_accuracies: accuracy –ø–æ —ç–ø–æ—Ö–∞–º
            - model: –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –≤–µ—Å–∞–º–∏
            - device: –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    """
    # --- üå± –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å ---
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

    # --- üñ•Ô∏è Device setup ---
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)

    # --- ‚öôÔ∏è –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ª–æ—Å—Å ---
    optimizer = optim.AdamW(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()
    # --- üìà –õ–æ–≥–∏ ---
    train_losses = []
    val_accuracies = []
    best_val_acc = 0.0
    best_model_wts = None
    weight_model_new = None
    bias_model_new = None

    # --- üîÅ –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è ---
    for epoch in range(epochs):
        # --- üü† –û–±—É—á–µ–Ω–∏–µ ---
        model.train()
        running_loss = 0.0
        progress_bar = tqdm(
            train_loader,
            desc=f"Epoch {epoch+1}/{epochs}",
            unit="batch",
            disable=not verbose,
            leave=False
        )

        for batch in progress_bar:
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤: (img, label, extra) –∏–ª–∏ (img, label)
            if len(batch) == 3:
                images, labels, extra = batch
            else:
                images, labels = batch
                extra = None

            images = images.to(device, non_blocking=True)
            labels = labels.to(device, non_blocking=True)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ extra
            if extra is not None:
                extra = extra.to(device, non_blocking=True)

            optimizer.zero_grad()
            if extra is not None:
                outputs = model(images, extra)
            else:
                outputs = model(images)

            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * images.size(0)
            progress_bar.set_postfix(loss=f"{loss.item():.4f}")
        epoch_loss = running_loss / len(train_loader.dataset)
        train_losses.append(epoch_loss)

        # --- üü¢ –í–∞–ª–∏–¥–∞—Ü–∏—è ---
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for batch in val_loader:
                if len(batch) == 3:
                    images, labels, extra = batch
                else:
                    images, labels = batch
                    extra = None

                images = images.to(device, non_blocking=True)
                labels = labels.to(device, non_blocking=True)

                if extra is not None:
                    extra = extra.to(device, non_blocking=True)
                    outputs = model(images, extra)
                else:
                    outputs = model(images)

                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        val_acc = correct / total
        val_accuracies.append(val_acc)
        # --- üèÜ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ ---
        if val_acc >= best_val_acc:
            best_val_acc = val_acc
            best_model_wts = model.state_dict().copy()

            last_conv = model.blocks[-1][0]
            weight_model_new = last_conv.weight  # [C_out, C_in, k, k]
            bias_model_new = last_conv.bias if last_conv.bias is not None else None

            if save_best_path:
                torch.save(best_model_wts, save_best_path)
                if verbose:
                    print(f"üî• Best model updated: val_acc = {val_acc:.4f}")

        # --- üì¢ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ---
        if verbose:
            print(f"Epoch [{epoch+1:2d}/{epochs}] | Loss: {epoch_loss:6.4f} | Val Acc: {val_acc:6.4f} | Best: {best_val_acc:6.4f}")

    # --- ‚úÖ –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å ---
    if best_model_wts is not None:
        model.load_state_dict(best_model_wts)

    # --- üì¶ –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ---
    return {
        "best_val_acc": best_val_acc,
        "train_losses": train_losses,
        "val_accuracies": val_accuracies,
        "model": model,
        "new_weight": weight_model_new,
        "new_bias": bias_model_new,  # –î–æ–±–∞–≤–ª–µ–Ω–æ
        "device": device,
    }
