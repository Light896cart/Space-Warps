from typing import List

import torch
import torch.nn as nn
from torch.utils.data import DataLoader

from src.model.model_architecture import ProgressiveModel
from src.model.train_eval import train_and_evaluate_model



def progressive_architecture_search(
    train_loader: DataLoader,
    val_loader: DataLoader,
    max_layers: int = 10,
    k_candidates: List[int] = None,
    epochs_per_eval: int = 5,
    lr: float = 1e-3,
    device: str = None,
    seed: int = 42,
    copy_weights:bool = True
):
    """
    –ü–æ—à–∞–≥–æ–≤–æ –Ω–∞—Ä–∞—â–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å, –≤—ã–±–∏—Ä–∞—è –Ω–∞–∏–ª—É—á—à–∏–π –±–ª–æ–∫ (–ø–æ val_acc) –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ.

    Args:
        train_loader, val_loader: –¥–∞–Ω–Ω—ã–µ
        max_layers: –º–∞–∫—Å. —á–∏—Å–ª–æ –±–ª–æ–∫–æ–≤
        k_candidates: —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π k (–∫–∞–Ω–∞–ª—ã = base_channels * k)
        epochs_per_eval: —Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö —É—á–∏—Ç—å –∫–∞–∂–¥—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç
        lr: learning rate
        device: cuda/cpu
        seed: –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å

    Returns:
        –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∏ –∏—Å—Ç–æ—Ä–∏—è –ø–æ–∏—Å–∫–∞
    """
    if k_candidates is None:
        k_candidates = [[3, 9, 27, 81]]  # –Ω–∞–ø—Ä–∏–º–µ—Ä

    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    # üå± –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    # üß± –ù–∞—á–∏–Ω–∞–µ–º —Å –ø—É—Å—Ç–æ–π –º–æ–¥–µ–ª–∏
    model = ProgressiveModel(extra_input_dim=0,class_data=2).to(device)
    best_candidate_state = None
    channel_image = 3
    best_val_acc = 0.0
    best_k = None
    best_c = None
    history = []
    print("üîç –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã...")
    for quantity_blocks in range(len(k_candidates)):
        print(f"\n--- [–®–∞–≥ {quantity_blocks + 1}] –ü–æ–¥–±–æ—Ä —Å–ª–µ–¥—É—é—â–µ–≥–æ –±–ª–æ–∫–∞ ---")
        # log_system_usage(f"–ù–∞—á–∞–ª–æ —à–∞–≥–∞ {quantity_blocks + 1}")
        weight_model = None
        best_acc_for_layer = 0.0
        bias_model = None
        for i,candidat in enumerate(k_candidates[quantity_blocks]):
            # log_system_usage(f"–ü–µ—Ä–µ–¥ add_block {i+1}")
            out_channels = channel_image if quantity_blocks == 0 else model.blocks[-1][0].out_channels if i==0 else model.blocks[-2][0].out_channels
            model.add_block(out_channels,candidat,check_add=i)

            # log_system_usage(f"–ü–æ—Å–ª–µ add_block {i + 1}")
            # üîÅ –ü–µ—Ä–µ–Ω–æ—Å–∏–º –≤–µ—Å–∞, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ
            if weight_model is not None and len(model.blocks) > 0:
                target_conv = model.blocks[-1][0]  # –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ª–æ–π
                src_shape = weight_model.shape[1]  # [N, C, K, K] ‚Üí C = in_channels
                tgt_in_ch = target_conv.weight.shape[1]

                # –ï—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç ‚Äî —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞, –Ω–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ —Å–æ–≤–ø–∞–¥–∞—é—Ç
                # –ö–æ–ø–∏—Ä—É–µ–º –≤–µ—Å–∞ —Å —É—á—ë—Ç–æ–º —á–∏—Å–ª–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
                num_copy = min(target_conv.out_channels, weight_model.shape[0])

                # –ö–æ–ø–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ num_copy —Ñ–∏–ª—å—Ç—Ä–æ–≤
                with torch.no_grad():
                    target_conv.weight.data[:num_copy, :, :, :].copy_(weight_model[:num_copy, :, :, :])

                    # –ï—Å–ª–∏ —Ü–µ–ª–µ–≤–æ–π —Å–ª–æ–π –±–æ–ª—å—à–µ ‚Äî –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Å—Ç–∞—Ç–æ–∫
                    if target_conv.out_channels > num_copy:
                        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
                        new_filters = target_conv.out_channels - num_copy
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Kaiming –∏–ª–∏ –º–∞–ª—ã–π —à—É–º
                        nn.init.kaiming_normal_(
                            target_conv.weight.data[num_copy:, :, :, :],
                            mode='fan_in',
                            nonlinearity='relu'
                        )

            # üî¨ –û—Ü–µ–Ω–∏–≤–∞–µ–º (—Å —Ç–µ–º–∏ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏!)
            result = train_and_evaluate_model(
                model=model,
                train_loader=train_loader,
                val_loader=val_loader,
                epochs=epochs_per_eval,
                lr=lr,
                weight_model=weight_model,
                device=device,
                save_best_path=None,  # –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç
                verbose=True,
            )
            # log_system_usage(f"–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ {i + 1}")
            acc = result["best_val_acc"]
            if copy_weights:
                new_weight = result["new_weight"]
                new_bias = result["new_bias"]
                max_index = len(k_candidates[quantity_blocks]) - 1
                next_idx = min(i + 1, max_index)
                next_candidat = k_candidates[quantity_blocks][next_idx]
                number_repeat = next_candidat // candidat
                print(f'üîÅ number_repeat = {number_repeat} (candidat={candidat}, next={next_candidat})')
                weight_model = new_weight.detach().repeat(number_repeat, 1, 1, 1)  # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ detach()
                bias_model = new_bias.detach().repeat(number_repeat) if new_bias is not None else None
                # üî• –î–û–ë–ê–í–õ–Ø–ï–ú –°–õ–£–ß–ê–ô–ù–û–°–¢–¨: weight noise (jitter)
                # –®—É–º ~ N(0, œÉ), –≥–¥–µ œÉ = 0.1 * std(–≤–µ—Å–æ–≤)
                noise_std = 0.03 * weight_model.std()
                weight_model += torch.randn_like(weight_model) * noise_std

                # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è bias (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if bias_model is not None:
                    bias_noise_std = 0.1 * bias_model.std()
                    bias_model += torch.randn_like(bias_model) * bias_noise_std
            else:
                weight_model = None
                bias_model = None
            print(f"    ‚Üí val_acc = {acc:.4f}")
            if acc > best_acc_for_layer:
                best_acc_for_layer = acc
                best_k = candidat
                best_c = out_channels
                best_candidate_state = {k: v.detach().clone() for k, v in model.state_dict().items()} # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞
        # üèÅ –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—Ç–æ–∏—Ç –ª–∏ —Ä–∞—Å—Ç–∏
        weight_model = None
        # log_system_usage(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
        if best_acc_for_layer > best_val_acc:
            model.add_block(best_c, best_k, check_add=1)
            model.load_state_dict(best_candidate_state, strict=False)
            best_val_acc = best_acc_for_layer

            history.append({
                "layer": quantity_blocks + 1,
                "k": best_k,
                "channels": best_c,
                "val_acc": best_val_acc
            })

            print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –±–ª–æ–∫ {quantity_blocks + 1}: k={best_k} ‚Üí {best_c} –∫–∞–Ω–∞–ª–æ–≤, acc={best_val_acc:.4f}")
        else:
            print("‚ùå –ù–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è ‚Äî –æ—Å—Ç–∞–Ω–æ–≤.")
            break

    print(f"\n‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à—ë–Ω. –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {len(model.blocks)} –±–ª–æ–∫–æ–≤, acc={best_val_acc:.4f}")
    return model, history
