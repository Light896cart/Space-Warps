import random

import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim
import torch
import torch.nn as nn
import torch.nn.functional as F
from tqdm import tqdm
from torch.utils.data import DataLoader, random_split

from src.model.model_architecture import ProgressiveModel
from src.preprocessing.augmentation import train_transformer
from src.utils.dataset import Space_Galaxi
from torchvision import transforms

def set_seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

# –ü—Ä–æ—Å—Ç–æ–π transforms: –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä
transform = transforms.Compose([
    transforms.ToTensor(),          # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Ç–µ–Ω–∑–æ—Ä PyTorch
    transforms.Normalize(mean=[0.1], std=[0.15])
])

# –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø—É—Ç–∏
csv_path = r'D:\Code\Space_Warps\data\reg\balanced_2001_by_class_cycle.csv'
img_dir_path = r'D:\Code\Space_Warps\data\image_data\img_csv'

# üü¢ –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç –î–í–ê–ñ–î–´ ‚Äî —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏
train_dataset_full = Space_Galaxi(csv_path, img_dir_path=img_dir_path, transform=train_transformer)
val_dataset_full = Space_Galaxi(csv_path, img_dir_path=img_dir_path, transform=transform)

# –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä
total_size = len(train_dataset_full)

# –ë–µ—Ä—ë–º 100% –¥–∞–Ω–Ω—ã—Ö (–∏–ª–∏ 5%, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –º–∞–ª–µ–Ω—å–∫–∏–π —Å–µ—Ç)
subset_size = int(1.0 * total_size)  # –∏–ª–∏ int(0.05 * total_size)
remaining = total_size - subset_size

# –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞
indices = list(range(total_size))
random.shuffle(indices)
subset_indices = indices[:subset_size]

# –†–∞–∑–±–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –Ω–∞ train/val
train_val_split = int(0.9 * len(subset_indices))
train_indices = subset_indices[:train_val_split]
val_indices = subset_indices[train_val_split:]

# --- –°–æ–∑–¥–∞—ë–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ transform ---
train_subset = torch.utils.data.Subset(train_dataset_full, train_indices)
val_subset = torch.utils.data.Subset(val_dataset_full, val_indices)

train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)
# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ---
num_models = 19  # c –æ—Ç 1 –¥–æ 19
epochs = 20

# --- –°–ø–∏—Å–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –º–æ–¥–µ–ª—è–º ---
best_val_accs = []     # –ª—É—á—à–∞—è val_acc –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
best_val_losses = []   # —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π val_loss
arch_configs = []      # 3*c ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤

# --- –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ train_loader –∏ val_loader —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã ---
# –ü—Ä–∏–º–µ—Ä:
# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# --- –§—É–Ω–∫—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±–µ–∑ device) ---
def train_and_evaluate_model(model, train_loader, val_loader, epochs=10, lr=1e-3):
    model.train()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    best_val_acc = 0.0

    for epoch in range(epochs):
        # –û–±—É—á–µ–Ω–∏–µ
        for images, labels,extra in train_loader:
            optimizer.zero_grad()
            outputs = model(images,extra)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for images, labels,extra in val_loader:
                outputs = model(images,extra)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        val_acc = correct / total

        if val_acc > best_val_acc:
            best_val_acc = val_acc

        model.train()

    return best_val_acc

print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã")

model = ProgressiveModel()

best_val_acc = 0.0
in_channels = 1  # RGB
history = []     # –¥–ª—è –ª–æ–≥–æ–≤: (–≥–ª—É–±–∏–Ω–∞, k, –∫–∞–Ω–∞–ª—ã, acc)

print("üîç –ü–æ—à–∞–≥–æ–≤–æ–µ –Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

layer_idx = 0
max_layers = 10  # –∑–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞

while layer_idx < max_layers:
    print(f"\n--- –ü–æ–ø—ã—Ç–∫–∞ –¥–æ–±–∞–≤–∏—Ç—å —Å–ª–æ–π {layer_idx + 1} ---")
    best_k = None
    best_c = None
    best_acc_for_layer = 0.0
    c = 3
    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º k –æ—Ç 1 –¥–æ 20 ‚Üí –∫–∞–Ω–∞–ª—ã = 3*k
    for k in range(3):
        c = 3 * c
        # –ö–æ–ø–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å + –¥–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫
        candidate = ProgressiveModel()
        # –í–æ—Å—Å–æ–∑–¥–∞—ë–º –≤—Å–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–ª–æ–∏
        prev_out = in_channels
        for block in model.blocks:
            in_ch = block[0].in_channels
            out_ch = block[0].out_channels
            candidate.add_block(in_ch, out_ch)
            prev_out = out_ch
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –±–ª–æ–∫
        candidate.add_block(prev_out, c)

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º
        acc = train_and_evaluate_model(candidate, train_loader, val_loader, epochs=8)
        print(f"  –°–ª–æ–π {layer_idx+1}, k={k} ‚Üí {c} –∫–∞–Ω–∞–ª–æ–≤: val_acc = {acc:.4f}")

        if acc > best_acc_for_layer:
            best_acc_for_layer = acc
            best_k = k
            best_c = c

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É–ª—É—á—à–∏–ª–æ—Å—å –ª–∏
    if best_acc_for_layer > best_val_acc:
        # –î–æ–±–∞–≤–ª—è–µ–º –ª—É—á—à–∏–π –±–ª–æ–∫ –≤ —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
        model.add_block(in_channels if layer_idx == 0 else model.blocks[-1][0].out_channels, best_c)
        best_val_acc = best_acc_for_layer
        history.append((layer_idx + 1, best_k, best_c, best_val_acc))
        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å–ª–æ–π {layer_idx + 1}: k={best_k} ‚Üí {best_c} –∫–∞–Ω–∞–ª–æ–≤, acc = {best_val_acc:.4f}")
        layer_idx += 1
    else:
        print("‚ùå –ù–æ–≤—ã–π —Å–ª–æ–π –Ω–µ —É–ª—É—á—à–∏–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è.")
        break

# ===================================================
# 6. –ò—Ç–æ–≥
# ===================================================
if layer_idx == 0:
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –¥–∞–∂–µ –æ–¥–∏–Ω —Å–ª–æ–π.")
else:
    print("\n" + "="*60)
    print("üèÜ –§–ò–ù–ê–õ–¨–ù–ê–Ø –ú–û–î–ï–õ–¨")
    print(f"üîπ –ì–ª—É–±–∏–Ω–∞: {len(model.blocks)} —Å–ª–æ—è")
    print(f"üîπ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {best_val_acc:.4f}")
    print("üîπ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:")
    for depth, k, c, acc in history:
        print(f"   –°–ª–æ–π {depth}: k={k} ‚Üí {c} –∫–∞–Ω–∞–ª–æ–≤, val_acc = {acc:.4f}")
    print("="*60)

    # –ì—Ä–∞—Ñ–∏–∫
    depths = [h[0] for h in history]
    channels = [h[2] for h in history]
    plt.figure(figsize=(10, 4))
    plt.bar(depths, channels, color='lightgreen', edgecolor='k')
    plt.title('–ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–∫–∞–Ω–∞–ª—ã = 3*k)')
    plt.xlabel('–ù–æ–º–µ—Ä —Å–ª–æ—è')
    plt.ylabel('–ß–∏—Å–ª–æ –∫–∞–Ω–∞–ª–æ–≤')
    plt.xticks(depths)
    plt.grid(axis='y', alpha=0.3)
    plt.show()