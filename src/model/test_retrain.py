def progressive_architecture_search(
    train_loader: DataLoader,
    val_loader: DataLoader,
    max_layers: int = 10,
    k_candidates: List[int] = None,
    epochs_per_eval: int = 5,
    lr: float = 1e-3,
    device: str = None,
    seed: int = 42,
    copy_weights:bool = True

):
    """
    –ü–æ—à–∞–≥–æ–≤–æ –Ω–∞—Ä–∞—â–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å, –≤—ã–±–∏—Ä–∞—è –Ω–∞–∏–ª—É—á—à–∏–π –±–ª–æ–∫ (–ø–æ val_acc) –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ.

    Args:
        train_loader, val_loader: –¥–∞–Ω–Ω—ã–µ
        max_layers: –º–∞–∫—Å. —á–∏—Å–ª–æ –±–ª–æ–∫–æ–≤
        k_candidates: —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π k (–∫–∞–Ω–∞–ª—ã = base_channels * k)
        epochs_per_eval: —Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö —É—á–∏—Ç—å –∫–∞–∂–¥—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç
        lr: learning rate
        device: cuda/cpu
        seed: –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å

    Returns:
        –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∏ –∏—Å—Ç–æ—Ä–∏—è –ø–æ–∏—Å–∫–∞
    """
    if k_candidates is None:
        k_candidates = [3, 9, 27, 81]  # –Ω–∞–ø—Ä–∏–º–µ—Ä

    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    # üå± –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    # üß± –ù–∞—á–∏–Ω–∞–µ–º —Å –ø—É—Å—Ç–æ–π –º–æ–¥–µ–ª–∏
    model = ProgressiveModel(extra_input_dim=0,class_data=2).to(device)
    channel_image = 3
    for quantity_blocks in range(max_layers):
        weight_model = None
        best_k = None
        best_c = None
        best_candidate_state = None
        best_acc_for_layer = 0.0
        bias_model = None
        for i,candidat in enumerate(k_candidates):
            model.add_block(channel_image,candidat,check_add=i)

            if weight_model is not None:
                model.blocks[-1][0].weight.data.copy_(weight_model)
            # üî¨ –û—Ü–µ–Ω–∏–≤–∞–µ–º (—Å —Ç–µ–º–∏ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏!)
            result = train_and_evaluate_model(
                model=model,
                train_loader=train_loader,
                val_loader=val_loader,
                epochs=epochs_per_eval,
                lr=lr,
                weight_model=weight_model,
                device=device,
                save_best_path=None,  # –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç
                verbose=True,
            )
            acc = result["best_val_acc"]
            if copy_weights:
                new_weight = result["new_weight"]
                new_bias = result["new_bias"]
                weight_model = new_weight.detach().repeat(3, 1, 1, 1)  # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ detach()
                bias_model = new_bias.detach().repeat(3) if new_bias is not None else None
                # üî• –î–û–ë–ê–í–õ–Ø–ï–ú –°–õ–£–ß–ê–ô–ù–û–°–¢–¨: weight noise (jitter)
                # –®—É–º ~ N(0, œÉ), –≥–¥–µ œÉ = 0.1 * std(–≤–µ—Å–æ–≤)
                noise_std = 0.03 * weight_model.std()
                weight_model += torch.randn_like(weight_model) * noise_std

                # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è bias (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if bias_model is not None:
                    bias_noise_std = 0.1 * bias_model.std()
                    bias_model += torch.randn_like(bias_model) * bias_noise_std
            else:
                weight_model = None
                bias_model = None
            print(f"    ‚Üí val_acc = {acc:.4f}")
            if acc > best_acc_for_layer:
                best_acc_for_layer = acc
                best_k = candidat
                best_c = channel_image
                best_candidate_state = {k: v.detach().clone() for k, v in model.state_dict().items()} # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞
                print(f'–ù–£ –≠–¢–û –°–û–•–†–ê–ù–ï–ù–ö–ê {best_candidate_state}')
                print(f'–ù–£ –≠–¢–û –°–û–•–†–ê–ù–ï–ù–ö–ê shav{best_candidate_state.shape}')
