from typing import Optional, Tuple

import pandas as pd
import torch
from pathlib import Path
from torchvision.transforms import InterpolationMode
from torch.utils.data import DataLoader, Dataset

from src.data.dataset import Subset
from src.preprocessing.augmentation import train_transformer
from torchvision import transforms


def create_train_val_dataloaders(
    csv_path: Optional[str] = None,
    img_dir_path: Optional[str] = None,
    train_transform: Optional[transforms.Compose] = None,
    val_transform: Optional[transforms.Compose] = None,
    fraction: float = 1.0,
    train_ratio: float = 0.9,
    batch_size: int = 64,
    seed: int = 42,
    num_workers: int = 3,
    pin_memory: bool = False,
    dataset: Dataset = None,
) -> Tuple[DataLoader, DataLoader]:
    """
        –°–æ–∑–¥–∞—ë—Ç DataLoader'—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏,
        –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–æ–ª–∏ –¥–∞–Ω–Ω—ã—Ö, –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º.

        Args:
            csv_path: –ü—É—Ç—å –∫ CSV —Å –º–µ—Ç–∫–∞–º–∏. –ï—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç.
            img_dir_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
            train_transform: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è train (augmentations). –ï—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç.
            val_transform: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è val (–±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π). –ï—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç.
            fraction: –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.1 –¥–ª—è 10%).
            train_ratio: –î–æ–ª—è train –≤ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ (–æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî val).
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞.
            seed: Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏.
            num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
            pin_memory: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ pinned memory (—É—Å–∫–æ—Ä—è–µ—Ç –ø–µ—Ä–µ–¥–∞—á—É –Ω–∞ GPU).

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (train_loader, val_loader)

        Raises:
            FileNotFoundError: –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω CSV –∏–ª–∏ –ø–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
            ValueError: –ü—Ä–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö.
        """
    # --- –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ---
    if not 0.0 < fraction <= 1.0:
        raise ValueError(f"fraction must be in (0, 1], got {fraction}")
    if not 0.0 < train_ratio < 1.0:
        raise ValueError(f"train_ratio must be in (0, 1), got {train_ratio}")
    if batch_size <= 0:
        raise ValueError(f"batch_size must be positive, got {batch_size}")

    # --- üìÅ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–µ–π ---

    if csv_path is None:
        csv_path = r'D:\Code\Space_Warps\data\reg\balanced_2001_by_class_cycle.csv'
    else:
        csv_path = Path(csv_path)

    if img_dir_path is None:
        img_dir_path = r'D:\Code\Space_Warps\data\image_data\img_csv'
    else:
        img_dir_path = Path(img_dir_path)

    if not csv_path:
        raise FileNotFoundError(f"CSV file not found: {csv_path}")
    if not img_dir_path:
        raise FileNotFoundError(f"Image directory not found: {img_dir_path}")

    # --- –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ ---
    if val_transform is None:
        val_transform = transforms.Compose([
            transforms.Resize((224, 224), interpolation=InterpolationMode.BILINEAR),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])
    if train_transform is None:
        train_transform = train_transformer

    # --- üß© –°–æ–∑–¥–∞—ë–º –æ–¥–∏–Ω –¥–∞—Ç–∞—Å–µ—Ç –±–µ–∑ transform (–±—É–¥–µ–º –ø—Ä–∏–º–µ–Ω—è—Ç—å —á–µ—Ä–µ–∑ collate_fn –∏–ª–∏ –≤ Subset?) ---
    # –ù–æ –ª—É—á—à–µ: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω –¥–∞—Ç–∞—Å–µ—Ç, –∞ transform –∑–∞–¥–∞–≤–∞—Ç—å –≤ Subset —á–µ—Ä–µ–∑ –æ–±—ë—Ä—Ç–∫—É
    # –û–¥–Ω–∞–∫–æ PyTorch –Ω–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–µ–Ω—è—Ç—å transform —É Subset –Ω–∞–ø—Ä—è–º—É—é ‚Üí –æ–±—Ö–æ–¥: –¥–µ—Ä–∂–∞—Ç—å –¥–≤–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞, –Ω–æ —Å shared data

    # üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω —Ä–∞–∑ —á—Ç–µ–Ω–∏–µ CSV, –∫—ç—à–∏—Ä—É–µ–º –º–µ—Ç–∫–∏
    df = pd.read_csv(csv_path)
    # total_size = len(df)
    total_size = 25000

    subset_size = int(fraction * total_size)
    if subset_size == 0:
        raise ValueError("Fraction is too small, subset_size = 0")

    # --- üîÅ –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ ---
    generator = torch.Generator().manual_seed(seed)
    indices = torch.randperm(total_size, generator=generator).tolist()
    subset_indices = indices[:subset_size]

    train_split = int(train_ratio * len(subset_indices))
    train_indices = subset_indices[:train_split]
    val_indices = subset_indices[train_split:]

    if len(train_indices) == 0:
        raise ValueError("Train split is empty after applying fraction and ratio.")
    if len(val_indices) == 0:
        raise ValueError("Validation split is empty after applying fraction and ratio.")

# --- üì¶ –î–≤–∞ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏ ---
    # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ: –æ–Ω–∏ –¥–µ–ª—è—Ç –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –≥—Ä—É–∑–∏—Ç –≤—Å—ë –≤ –ø–∞–º—è—Ç—å —Å—Ä–∞–∑—É)
    train_dataset = dataset(csv_path=str(csv_path), img_dir_path=str(img_dir_path), transform=train_transform)
    val_dataset = dataset(csv_path=str(csv_path), img_dir_path=str(img_dir_path), transform=val_transform)

    train_subset = Subset(train_dataset, train_indices)
    val_subset = Subset(val_dataset, val_indices)

    # --- üöö DataLoader ---
    train_loader = DataLoader(
        train_subset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
        generator=generator,
    )

    val_loader = DataLoader(
        val_subset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
        generator=generator,
    )

    print(f"‚úÖ DataLoader created:")
    print(f"   Total dataset size: {total_size}")
    print(f"   Used fraction: {fraction:.1%} ‚Üí {subset_size} samples")
    print(f"   Train: {len(train_indices)} | Val: {len(val_indices)}")
    print(f"   Batch size: {batch_size}, Workers: {num_workers}")

    return train_loader, val_loader