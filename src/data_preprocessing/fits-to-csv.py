# -*- coding: utf-8 -*-
"""
–õ–µ–Ω–∏–≤–æ–µ —á—Ç–µ–Ω–∏–µ spAll-v6_1_3.fits –∏ —Å–æ–∑–¥–∞–Ω–∏–µ CSV —Ñ–∞–π–ª–æ–≤ –ø–æ N —Å—Ç—Ä–æ–∫.
–ò–∑–≤–ª–µ–∫–∞—é—Ç—Å—è —Å—Ç–æ–ª–±—Ü—ã: specObjID, RA, DEC.
"""

import os
from astropy.io import fits
import pandas as pd


def lazy_create_csv_chunks(fits_filename, chunk_size=1000, output_dir='spall_csv_chunks'):
    """
    –õ–µ–Ω–∏–≤–æ–µ —á—Ç–µ–Ω–∏–µ spAll FITS —Ñ–∞–π–ª–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ CSV —Ñ–∞–π–ª–æ–≤ –ø–æ N —Å—Ç—Ä–æ–∫.
    –ü–æ–ª—è: id, ra, dec, class, subclass, z, z_err.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    fits_filename (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É spAll-v6_1_3.fits.
    chunk_size (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ –∫–∞–∂–¥–æ–º CSV —Ñ–∞–π–ª–µ.
    output_dir (str): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è CSV —Ñ–∞–π–ª–æ–≤.
    """

    import os
    import pandas as pd
    from astropy.io import fits

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    os.makedirs(output_dir, exist_ok=True)

    print(f"–û—Ç–∫—Ä—ã–≤–∞–µ–º {fits_filename}...")

    with fits.open(fits_filename, memmap=True) as hdul:
        hdu = hdul[1]  # BinTableHDU

        try:
            total_rows = len(hdu.data)
        except TypeError:
            total_rows = hdu.data.shape[0]

        print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {total_rows}")

        # --- –ü–æ–∏—Å–∫ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ ---
        colnames = [col.name for col in hdu.columns]

        print(colnames)

        col_mapping = {
            'id': ['SPECOBJID', 'specobjid'],
            'ra': ['PLUG_RA', 'RA', 'plug_ra', 'ra'],
            'dec': ['PLUG_DEC', 'DEC', 'plug_dec', 'dec', 'DECCAT'],
            'class': ['CLASS', 'class'],
            'subclass': ['SUBCLASS', 'subclass'],
            'z': ['Z', 'z'],
            'z_err': ['Z_ERR', 'z_err', 'ZERROR']
        }

        col_idx = {}
        for key, names in col_mapping.items():
            col_idx[key] = None
            for name in names:
                if name in colnames:
                    col_idx[key] = colnames.index(name)
                    print(f"‚úÖ {key} -> '{name}' (–∏–Ω–¥–µ–∫—Å {col_idx[key]})")
                    break
            if col_idx[key] is None:
                print(f"‚ùå {key} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏.")
                return  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–ª–µ

        # –ü—Ä–æ–≤–µ—Ä–∏–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        required = ['id', 'ra', 'dec', 'class', 'z', 'z_err']
        for key in required:
            if col_idx[key] is None:
                print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ '{key}'")
                return

        # --- –ß—Ç–µ–Ω–∏–µ –∏ –∑–∞–ø–∏—Å—å —á–∞–Ω–∫–æ–≤ ---
        file_counter = 1
        buffer = []

        for i in range(total_rows):
            try:
                record = hdu.data[i]
            except Exception as e:
                continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∏—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏

            try:
                row = {
                    'id': record[col_idx['id']],
                    'ra': record[col_idx['ra']],
                    'dec': record[col_idx['dec']],
                    'class': record[col_idx['class']],
                    'subclass': record[col_idx['subclass']],
                    'z': record[col_idx['z']],
                    'z_err': record[col_idx['z_err']]
                }
                buffer.append(row)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ {i}: {e}")
                continue

            if len(buffer) >= chunk_size:
                filename = os.path.join(output_dir, f"chunk_{file_counter:04d}.csv")
                pd.DataFrame(buffer).to_csv(filename, index=False)
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")
                buffer = []
                file_counter += 1

        # –ü–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
        if buffer:
            filename = os.path.join(output_dir, f"chunk_{file_counter:04d}.csv")
            pd.DataFrame(buffer).to_csv(filename, index=False)
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ (–æ—Å—Ç–∞—Ç–æ–∫): {filename}")

    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ: {file_counter - 1} —Ñ–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–æ.")

output_dir = r'D:\Code\Space_Warps\data\raw_data'
# --- –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å ---
if __name__ == "__main__":
    fits_file_path = r'D:\Code\Space_Warps\spAll-v6_1_3.fits'

    if not os.path.exists(fits_file_path):
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª '{fits_file_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    else:
        lazy_create_csv_chunks(fits_file_path, chunk_size=1000, output_dir=output_dir)
